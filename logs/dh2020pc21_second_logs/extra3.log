Opening config.ini...
MAX_IMAGES: 18000
BATCH_SIZE: 18
LEARNING_RATE: 5e-05
EPOCHS: 100
TRANSFORM: RandomCrop
IMAGE_DIMEN: 256
EVALUATION_IMAGES: ['_gcgraos355QHyu7iFMK1w', '_QDf_pTzs-sEyBubXqmqxA', '_wbVgGy7xrO_C_gsz-BCvA', 'FYoB0UGu40k9nKurB8pucw', '1pFw6qQwFQ__QdnYYB7YLA', '-C-x3xSPFIEjqbyVC5PRaQ', '_Uu1yfgmkbji9nkUT3Tikw', '_nDuQstcKZ714CoL0G5iZg']
CHECKPOINT_SAVE_INTERVAL: 10
MODEL_LOCATION: /virtual/drosari3/models/model-18000-RandomCrop-256-18-5e-05-100-wCE
MODEL_NAME: model-18000-RandomCrop-256-18-5e-05-100-wCE
Training model-18000-RandomCrop-256-18-5e-05-100-wCE...
epochs=100 lr=5e-05, error=<function cross_entropy at 0x7f52877da170>
    [0] Processed 0/1000 batches (0.00%)
Traceback (most recent call last):
  File "/virtual/drosari3/csc490-mapillary-vistas/main.py", line 78, in <module>
    TRAINED_MODEL, TRAINING_LOSSES, TRAINING_ACCURACIES = train_model(model=model, 
  File "/virtual/drosari3/csc490-mapillary-vistas/train.py", line 52, in train_model
    loss = criterion(outputs, masks, weight=weights) + 0.5 * criterion2(outputs, masks)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/student/drosari3/.local/lib/python3.10/site-packages/segmentation_models_pytorch/losses/dice.py", line 106, in forward
    scores = self.compute_score(y_pred, y_true.type_as(y_pred), smooth=self.smooth, eps=self.eps, dims=dims)
  File "/student/drosari3/.local/lib/python3.10/site-packages/segmentation_models_pytorch/losses/dice.py", line 130, in compute_score
    return soft_dice_score(output, target, smooth, eps, dims)
  File "/student/drosari3/.local/lib/python3.10/site-packages/segmentation_models_pytorch/losses/_functional.py", line 181, in soft_dice_score
    intersection = torch.sum(output * target, dim=dims)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 298.00 MiB (GPU 0; 7.78 GiB total capacity; 6.01 GiB already allocated; 287.00 MiB free; 7.08 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
