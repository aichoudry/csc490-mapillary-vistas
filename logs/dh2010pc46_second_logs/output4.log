Opening config.ini...
MAX_IMAGES: 18000
BATCH_SIZE: 20
LEARNING_RATE: 5e-05
EPOCHS: 100
TRANSFORM: RandomCrop
IMAGE_DIMEN: 256
EVALUATION_IMAGES: ['_gcgraos355QHyu7iFMK1w', '_QDf_pTzs-sEyBubXqmqxA', '_wbVgGy7xrO_C_gsz-BCvA', 'FYoB0UGu40k9nKurB8pucw', '1pFw6qQwFQ__QdnYYB7YLA', '-C-x3xSPFIEjqbyVC5PRaQ', '_Uu1yfgmkbji9nkUT3Tikw', '_nDuQstcKZ714CoL0G5iZg']
CHECKPOINT_SAVE_INTERVAL: 10
MODEL_LOCATION: /virtual/drosari3/models/model-18000-RandomCrop-256-20-5e-05-100-wCE
MODEL_NAME: model-18000-RandomCrop-256-20-5e-05-100-wCE
Training model-18000-RandomCrop-256-20-5e-05-100-wCE...
epochs=100 lr=5e-05, error=<function cross_entropy at 0x7f3804b237f0>
    [0] Processed 0/900 batches (0.00%)
    [0] Processed 270/900 batches (30.00%)
    [0] Processed 540/900 batches (60.00%)
    [0] Processed 810/900 batches (90.00%)
Checkpoint 1 saved to /virtual/drosari3/models/model-18000-RandomCrop-256-20-5e-05-100-wCE/checkpoints/checkpoint_epoch_1.pth
[20:47:18] Epoch [1/100] Loss: 3.4730 Accuracy: 42.13%
    [1] Processed 0/900 batches (0.00%)
    [1] Processed 270/900 batches (30.00%)
    [1] Processed 540/900 batches (60.00%)
    [1] Processed 810/900 batches (90.00%)
[21:11:51] Epoch [2/100] Loss: 3.1818 Accuracy: 51.63%
    [2] Processed 0/900 batches (0.00%)
    [2] Processed 270/900 batches (30.00%)
    [2] Processed 540/900 batches (60.00%)
    [2] Processed 810/900 batches (90.00%)
[21:37:18] Epoch [3/100] Loss: 3.1147 Accuracy: 54.22%
    [3] Processed 0/900 batches (0.00%)
    [3] Processed 270/900 batches (30.00%)
    [3] Processed 540/900 batches (60.00%)
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py", line 1132, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/usr/lib/python3.10/queue.py", line 180, in get
    self.not_empty.wait(remaining)
  File "/usr/lib/python3.10/threading.py", line 324, in wait
    gotit = waiter.acquire(True, timeout)
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 1185487) is killed by signal: Killed. 

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/virtual/drosari3/csc490-mapillary-vistas/main.py", line 78, in <module>
    TRAINED_MODEL, TRAINING_LOSSES, TRAINING_ACCURACIES = train_model(model=model, 
  File "/virtual/drosari3/csc490-mapillary-vistas/train.py", line 38, in train_model
    for batch_index, (images, masks) in enumerate(training_loader):
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py", line 633, in __next__
    data = self._next_data()
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py", line 1328, in _next_data
    idx, data = self._get_data()
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py", line 1284, in _get_data
    success, data = self._try_get_data()
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py", line 1145, in _try_get_data
    raise RuntimeError('DataLoader worker (pid(s) {}) exited unexpectedly'.format(pids_str)) from e
RuntimeError: DataLoader worker (pid(s) 1185487) exited unexpectedly
