{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from mapillary_vistas_dataset import MapillaryVistasDataset\n",
    "\n",
    "MAX_IMAGES = 2000\n",
    "IMAGE_DIMEN = 256\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "IMAGE_TRANSFORM = transforms.Compose([\n",
    "    transforms.CenterCrop(IMAGE_DIMEN),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "MAKS_TRANSFORM = transforms.Compose([\n",
    "    transforms.CenterCrop(IMAGE_DIMEN)\n",
    "])\n",
    "\n",
    "TRAINING_DATASET_NAME = f\"{MAX_IMAGES}-{IMAGE_DIMEN}-{BATCH_SIZE}-crop\"\n",
    "training_dataset = MapillaryVistasDataset(MapillaryVistasDataset.TRAINING,\n",
    "                                          max_images=MAX_IMAGES,\n",
    "                                          transform=IMAGE_TRANSFORM,\n",
    "                                          mask_transform=MAKS_TRANSFORM)\n",
    "training_loader = DataLoader(training_dataset, batch_size=BATCH_SIZE, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unet import UNet\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm.notebook import tqdm\n",
    "from train import train_model\n",
    "\n",
    "LEARNING_RATE = 0.001\n",
    "EPOCHS = 50\n",
    "CRITERION = F.cross_entropy\n",
    "\n",
    "LOAD_CHECKPOINT_PATH = None\n",
    "\n",
    "MODEL_NAME = f\"unet-{TRAINING_DATASET_NAME}-{EPOCHS}-{str(LEARNING_RATE).replace('.', '')}\"\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = UNet(in_channels=3, out_channels=len(MapillaryVistasDataset.color_to_i)).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "\n",
    "LOAD_CHECKPOINT_PATH = None\n",
    "\n",
    "model_info = train_model(model=model, \n",
    "                                 epochs=EPOCHS, \n",
    "                                 learning_rate=LEARNING_RATE, \n",
    "                                 criterion=CRITERION, \n",
    "                                 training_loader=training_loader, \n",
    "                                 optimizer=optimizer, \n",
    "                                 device=torch.device('cuda' if torch.cuda.is_available() else 'cpu'), \n",
    "                                 name=MODEL_NAME, \n",
    "                                 checkpoint_path=LOAD_CHECKPOINT_PATH, \n",
    "                                 save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading /virtual/csc490_mapillary/models/unet-5000-256-16-crop-50-0001/unet-5000-256-16-crop-50-0001.pth...\n"
     ]
    }
   ],
   "source": [
    "from evaluation import evaluate_model\n",
    "from mapillary_vistas_dataset import MapillaryVistasDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "SAVED_MODEL_NAME = MODEL_NAME #\"unet-256-crop-50-2000-001\"\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if SAVED_MODEL_NAME:\n",
    "    saved_model_path = f\"/virtual/csc490_mapillary/models/{SAVED_MODEL_NAME}/{SAVED_MODEL_NAME}.pth\"\n",
    "    print(f\"Evaluating {saved_model_path}...\")\n",
    "    model = UNet(in_channels=3, out_channels=MapillaryVistasDataset.NUM_CLASSES).to(device)\n",
    "    model_info = torch.load(saved_model_path)\n",
    "    model.load_state_dict(model_info['state_dict'])\n",
    "    print(f\"Accuracies: {model_info['accuracies']}\")\n",
    "    print(f\"Losses: {model_info['losses']}\")\n",
    "else:\n",
    "    print(f\"Evaluating {SAVED_MODEL_NAME}..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "validation_dataset = MapillaryVistasDataset(MapillaryVistasDataset.VALIDATION,\n",
    "                                            transform=IMAGE_TRANSFORM,\n",
    "                                            mask_transform=MAKS_TRANSFORM)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "mIoU_value = evaluate_model(model, \n",
    "                            validation_loader, \n",
    "                            device, \n",
    "                            MapillaryVistasDataset.NUM_CLASSES)\n",
    "print(f\"Validation mIoU: {mIoU_value:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
