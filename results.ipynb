{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Testing the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "def label_to_rgb(mask_tensor, color_map):\n",
    "    # Create an empty RGB image\n",
    "\n",
    "    rgb_image = torch.zeros(3, mask_tensor.shape[-2], mask_tensor.shape[-1], dtype=torch.uint8)\n",
    "\n",
    "    # Map each label to its RGB color\n",
    "    for label, color in color_map.items():\n",
    "        for channel, intensity in enumerate(color):\n",
    "            rgb_image[channel][mask_tensor == label] = intensity\n",
    "\n",
    "    return rgb_image\n",
    "\n",
    "def display_results(input_image_path, ground_truth_image_path, model, color_map):\n",
    "    # Load and process the input image\n",
    "\n",
    "    crop_size = 1024\n",
    "    input_image = Image.open(input_image_path).convert(\"RGB\")\n",
    "    transform = transforms.Compose([\n",
    "        transforms.CenterCrop(crop_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    input_tensor = transform(input_image).unsqueeze(0).to(device)\n",
    "\n",
    "    # Get model prediction\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        prediction = model(input_tensor)\n",
    "    _, predicted_mask = torch.max(prediction, 1)\n",
    "\n",
    "    # Convert tensor to color-coded image\n",
    "    predicted_rgb = label_to_rgb(predicted_mask.squeeze(0).cpu(), color_map)\n",
    "    predicted_image = transforms.ToPILImage()(predicted_rgb)\n",
    "\n",
    "    # Display results\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "    # Display input image\n",
    "\n",
    "    transform = transforms.Compose([transforms.CenterCrop(crop_size)])\n",
    "\n",
    "    axes[0].imshow(transform(input_image))\n",
    "    axes[0].set_title(\"Input Image\")\n",
    "    axes[0].axis(\"off\")\n",
    "\n",
    "    # Display predicted mask\n",
    "    axes[1].imshow((predicted_image))\n",
    "    axes[1].set_title(\"Model Prediction\")\n",
    "    axes[1].axis(\"off\")\n",
    "\n",
    "    # Display ground truth, if provided\n",
    "    if ground_truth_image_path:\n",
    "        ground_truth = Image.open(ground_truth_image_path)\n",
    "        axes[2].imshow(transform(ground_truth), cmap=\"gray\")\n",
    "        axes[2].set_title(\"Ground Truth\")\n",
    "        axes[2].axis(\"off\")\n",
    "    else:\n",
    "        axes[2].remove()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mapillary_vistas_dataset import MapillaryVistasDataset\n",
    "from unet import UNet\n",
    "import torch\n",
    "\n",
    "SAVED_MODEL_NAME = \"unet-256-crop-50-2000-001\"\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if SAVED_MODEL_NAME:\n",
    "    saved_model_path = f\"/virtual/csc490_mapillary/models/{SAVED_MODEL_NAME}/{SAVED_MODEL_NAME}.pth\"\n",
    "    print(f\"Evaluating {saved_model_path}...\")\n",
    "    model = UNet(in_channels=3, out_channels=MapillaryVistasDataset.NUM_CLASSES).to(device)\n",
    "    model_info = torch.load(saved_model_path)\n",
    "    model.load_state_dict(model_info['state_dict'])\n",
    "    print(f\"Accuracies: {model_info['accuracies']}\")\n",
    "    print(f\"Losses: {model_info['losses']}\")\n",
    "else:\n",
    "    print(f\"Evaluating {SAVED_MODEL_NAME}..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your model is already loaded and on the correct device.\n",
    "ROOT_DIR = \"/virtual/csc490_mapillary/data_v12\"\n",
    "image = \"03G8WHFnNfiJR-457i0MWQ\"\n",
    "path_input_image = ROOT_DIR + f'/validation/images/{image}.jpg'\n",
    "path_labeled_image = ROOT_DIR + f'/validation/labels/{image}.png'\n",
    "display_results(path_input_image, path_labeled_image, model, MapillaryVistasDataset.i_to_color)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
